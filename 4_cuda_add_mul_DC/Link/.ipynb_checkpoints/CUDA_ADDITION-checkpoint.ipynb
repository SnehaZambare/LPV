{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ragv9OnCxtbx",
    "outputId": "ffef5e9f-c500-483f-de4d-6931a10b8fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w6grCF6PxweG",
    "outputId": "7e7958c7-16e3-4154-8463-ca80ca0e1a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
      "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to c:\\users\\hp\\appdata\\local\\temp\\pip-req-build-20r5x77h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git 'C:\\Users\\HP\\AppData\\Local\\Temp\\pip-req-build-20r5x77h'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PMWUMMwx9nc",
    "outputId": "099c0e8f-4cff-43e1-97bd-998b8ea29016"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created output directory at /content/src\n",
      "Out bin /content/result.out\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5c0h0Wzx_wL",
    "outputId": "3e7dc6c1-2a23-4d49-bc39-8ac576bcdc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given array A is =>\n",
      "383, 777, 793, 386, 649, 362, 690, 763, 540, 172, 211, 567, 782, 862, 67, 929, \n",
      "\n",
      "Given array B is =>\n",
      "886, 915, 335, 492, 421, 27, 59, 926, 426, 736, 368, 429, 530, 123, 135, 802, \n",
      "\n",
      "CPU sum is =>\n",
      "1269, 1692, 1128, 878, 1070, 389, 749, 1689, 966, 908, 579, 996, 1312, 985, 202, 1731, \n",
      "\n",
      "GPU sum is =>\n",
      "1269, 1692, 1128, 878, 1070, 389, 749, 1689, 966, 908, 579, 996, 1312, 985, 202, 1731, \n",
      "\n",
      "\n",
      "Error : 0\n",
      "Time Elapsed: 0.022464\n"
     ]
    }
   ],
   "source": [
    "%%cu\n",
    "#include <cstdlib>\n",
    "#include <iostream>\n",
    "\n",
    "#define checkCudaErrors(call)                                                                 \\\n",
    "    do {                                                                                      \\\n",
    "        cudaError_t err = call;                                                               \\\n",
    "        if (err != cudaSuccess) {                                                             \\\n",
    "            printf(\"CUDA error at %s %d: %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
    "            exit(EXIT_FAILURE);                                                               \\\n",
    "        }                                                                                     \\\n",
    "    } while (0)\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "// VectorAdd parallel function\n",
    "__global__ void vectorAdd(int *a, int *b, int *result, int n) {\n",
    "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    if (tid < n) {\n",
    "        result[tid] = a[tid] + b[tid];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int *a, *b, *c;\n",
    "    int *a_dev, *b_dev, *c_dev;\n",
    "    int n = 1 << 4;\n",
    "\n",
    "    a = new int[n];\n",
    "    b = new int[n];\n",
    "    c = new int[n];\n",
    "    int *d = new int[n];\n",
    "    int size = n * sizeof(int);\n",
    "    checkCudaErrors(cudaMalloc(&a_dev, size));\n",
    "    checkCudaErrors(cudaMalloc(&b_dev, size));\n",
    "    checkCudaErrors(cudaMalloc(&c_dev, size));\n",
    "\n",
    "    // Array initialization..You can use Randon function to assign values\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        a[i] = rand() % 1000;\n",
    "        b[i] = rand() % 1000;\n",
    "        d[i] = a[i] + b[i];  // calculating serial addition\n",
    "    }\n",
    "    cout << \"Given array A is =>\\n\";\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        cout << a[i] << \", \";\n",
    "    }\n",
    "    cout << \"\\n\\n\";\n",
    "\n",
    "    cout << \"Given array B is =>\\n\";\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        cout << b[i] << \", \";\n",
    "    }\n",
    "    cout << \"\\n\\n\";\n",
    "\n",
    "    cudaEvent_t start, end;\n",
    "\n",
    "    checkCudaErrors(cudaEventCreate(&start));\n",
    "    checkCudaErrors(cudaEventCreate(&end));\n",
    "\n",
    "    checkCudaErrors(cudaMemcpy(a_dev, a, size, cudaMemcpyHostToDevice));\n",
    "    checkCudaErrors(cudaMemcpy(b_dev, b, size, cudaMemcpyHostToDevice));\n",
    "    int threads = 1024;\n",
    "    int blocks = (n + threads - 1) / threads;\n",
    "    checkCudaErrors(cudaEventRecord(start));\n",
    "\n",
    "    // Parallel addition program\n",
    "    vectorAdd<<<blocks, threads>>>(a_dev, b_dev, c_dev, n);\n",
    "\n",
    "    checkCudaErrors(cudaEventRecord(end));\n",
    "    checkCudaErrors(cudaEventSynchronize(end));\n",
    "\n",
    "    float time = 0.0;\n",
    "    checkCudaErrors(cudaEventElapsedTime(&time, start, end));\n",
    "\n",
    "    checkCudaErrors(cudaMemcpy(c, c_dev, size, cudaMemcpyDeviceToHost));\n",
    "\n",
    "    // Calculate the error term.\n",
    "\n",
    "    cout << \"CPU sum is =>\\n\";\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        cout << d[i] << \", \";\n",
    "    }\n",
    "    cout << \"\\n\\n\";\n",
    "\n",
    "    cout << \"GPU sum is =>\\n\";\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        cout << c[i] << \", \";\n",
    "    }\n",
    "    cout << \"\\n\\n\";\n",
    "\n",
    "    int error = 0;\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        error += d[i] - c[i];\n",
    "        if (0 != (d[i] - c[i])) {\n",
    "            cout << \"Error at (\" << i << \") => GPU: \" << c[i] << \", CPU: \" << d[i] << \"\\n\";\n",
    "        }\n",
    "    }\n",
    "\n",
    "    cout << \"\\nError : \" << error;\n",
    "    cout << \"\\nTime Elapsed: \" << time;\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVQDX3URyDgD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
