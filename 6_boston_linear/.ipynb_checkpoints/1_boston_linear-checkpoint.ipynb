{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b05cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and visualization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1929858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57026/57026 [==============================] - 0s 3us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train , y_train), (X_test , y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "                                            path = 'boston_housing_npz',\n",
    "                                            test_split = 0.2,\n",
    "                                            seed = 42\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9ac790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((404, 13), numpy.ndarray),\n",
       " ((102, 13), numpy.ndarray),\n",
       " ((404,), numpy.ndarray),\n",
       " ((102,), numpy.ndarray))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data shape and type\n",
    "(X_train.shape, type(X_train)), (X_test.shape, type(X_test)), (y_train.shape, type(y_train)), (y_test.shape, type(y_test)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab15eee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.1</td>\n",
       "      <td>2.6463</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>395.50</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05644</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.758</td>\n",
       "      <td>32.9</td>\n",
       "      <td>4.0776</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6.065</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>390.91</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>385.09</td>\n",
       "      <td>17.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.279</td>\n",
       "      <td>74.5</td>\n",
       "      <td>4.0522</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>373.66</td>\n",
       "      <td>11.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.31827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.914</td>\n",
       "      <td>83.2</td>\n",
       "      <td>3.9986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>390.70</td>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.29090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.174</td>\n",
       "      <td>93.6</td>\n",
       "      <td>1.6119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>388.08</td>\n",
       "      <td>24.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.03841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.229</td>\n",
       "      <td>90.7</td>\n",
       "      <td>3.0993</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.33</td>\n",
       "      <td>12.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1      2    3      4      5     6       7     8      9     10  \\\n",
       "0  0.09178   0.0   4.05  0.0  0.510  6.416  84.1  2.6463   5.0  296.0  16.6   \n",
       "1  0.05644  40.0   6.41  1.0  0.447  6.758  32.9  4.0776   4.0  254.0  17.6   \n",
       "2  0.10574   0.0  27.74  0.0  0.609  5.983  98.8  1.8681   4.0  711.0  20.1   \n",
       "3  0.09164   0.0  10.81  0.0  0.413  6.065   7.8  5.2873   4.0  305.0  19.2   \n",
       "4  5.09017   0.0  18.10  0.0  0.713  6.297  91.8  2.3682  24.0  666.0  20.2   \n",
       "5  0.10153   0.0  12.83  0.0  0.437  6.279  74.5  4.0522   5.0  398.0  18.7   \n",
       "6  0.31827   0.0   9.90  0.0  0.544  5.914  83.2  3.9986   4.0  304.0  18.4   \n",
       "7  0.29090   0.0  21.89  0.0  0.624  6.174  93.6  1.6119   4.0  437.0  21.2   \n",
       "8  4.03841   0.0  18.10  0.0  0.532  6.229  90.7  3.0993  24.0  666.0  20.2   \n",
       "9  0.22438   0.0   9.69  0.0  0.585  6.027  79.7  2.4982   6.0  391.0  19.2   \n",
       "\n",
       "       11     12  \n",
       "0  395.50   9.04  \n",
       "1  396.90   3.53  \n",
       "2  390.11  18.07  \n",
       "3  390.91   5.52  \n",
       "4  385.09  17.27  \n",
       "5  373.66  11.97  \n",
       "6  390.70  18.33  \n",
       "7  388.08  24.16  \n",
       "8  395.33  12.87  \n",
       "9  396.90  14.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Data to DataFrame \n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "# Preview the training data\n",
    "X_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522479d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       404 non-null    float64\n",
      " 1   1       404 non-null    float64\n",
      " 2   2       404 non-null    float64\n",
      " 3   3       404 non-null    float64\n",
      " 4   4       404 non-null    float64\n",
      " 5   5       404 non-null    float64\n",
      " 6   6       404 non-null    float64\n",
      " 7   7       404 non-null    float64\n",
      " 8   8       404 non-null    float64\n",
      " 9   9       404 non-null    float64\n",
      " 10  10      404 non-null    float64\n",
      " 11  11      404 non-null    float64\n",
      " 12  12      404 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 41.2 KB\n",
      "________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       404 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.3 KB\n"
     ]
    }
   ],
   "source": [
    "# View summary of datasets\n",
    "X_train_df.info()\n",
    "print('_'*40)\n",
    "y_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3344759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.789989</td>\n",
       "      <td>11.568069</td>\n",
       "      <td>11.214059</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.554524</td>\n",
       "      <td>6.284824</td>\n",
       "      <td>69.119307</td>\n",
       "      <td>3.792258</td>\n",
       "      <td>9.660891</td>\n",
       "      <td>408.960396</td>\n",
       "      <td>18.481931</td>\n",
       "      <td>356.293020</td>\n",
       "      <td>12.825520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.132761</td>\n",
       "      <td>24.269648</td>\n",
       "      <td>6.925462</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>0.116408</td>\n",
       "      <td>0.723759</td>\n",
       "      <td>28.034606</td>\n",
       "      <td>2.142651</td>\n",
       "      <td>8.736073</td>\n",
       "      <td>169.685166</td>\n",
       "      <td>2.157322</td>\n",
       "      <td>92.058615</td>\n",
       "      <td>7.308772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.137000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>5.878750</td>\n",
       "      <td>45.475000</td>\n",
       "      <td>2.097050</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.085000</td>\n",
       "      <td>7.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.262660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.167500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>391.305000</td>\n",
       "      <td>11.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.717875</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.620500</td>\n",
       "      <td>94.425000</td>\n",
       "      <td>5.118000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>395.810000</td>\n",
       "      <td>17.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     3.789989   11.568069   11.214059    0.069307    0.554524    6.284824   \n",
       "std      9.132761   24.269648    6.925462    0.254290    0.116408    0.723759   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081960    0.000000    5.190000    0.000000    0.452000    5.878750   \n",
       "50%      0.262660    0.000000    9.690000    0.000000    0.538000    6.210000   \n",
       "75%      3.717875   12.500000   18.100000    0.000000    0.624000    6.620500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    69.119307    3.792258    9.660891  408.960396   18.481931  356.293020   \n",
       "std     28.034606    2.142651    8.736073  169.685166    2.157322   92.058615   \n",
       "min      2.900000    1.137000    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.475000    2.097050    4.000000  281.000000   17.400000  375.085000   \n",
       "50%     77.500000    3.167500    5.000000  330.000000   19.100000  391.305000   \n",
       "75%     94.425000    5.118000   24.000000  666.000000   20.200000  395.810000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  404.000000  \n",
       "mean    12.825520  \n",
       "std      7.308772  \n",
       "min      1.920000  \n",
       "25%      7.092500  \n",
       "50%     11.560000  \n",
       "75%     17.167500  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of numerical feature values across the samples\n",
    "X_train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a1b1f",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8a2867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.115681</td>\n",
       "      <td>0.394210</td>\n",
       "      <td>0.348815</td>\n",
       "      <td>0.521906</td>\n",
       "      <td>0.681970</td>\n",
       "      <td>0.241618</td>\n",
       "      <td>0.376561</td>\n",
       "      <td>0.423589</td>\n",
       "      <td>0.625738</td>\n",
       "      <td>0.897607</td>\n",
       "      <td>0.302511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.102650</td>\n",
       "      <td>0.242696</td>\n",
       "      <td>0.253866</td>\n",
       "      <td>0.239522</td>\n",
       "      <td>0.138678</td>\n",
       "      <td>0.288719</td>\n",
       "      <td>0.194973</td>\n",
       "      <td>0.379829</td>\n",
       "      <td>0.323827</td>\n",
       "      <td>0.229502</td>\n",
       "      <td>0.232131</td>\n",
       "      <td>0.202740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.137860</td>\n",
       "      <td>0.444098</td>\n",
       "      <td>0.438466</td>\n",
       "      <td>0.087361</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.179389</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.944992</td>\n",
       "      <td>0.143481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338343</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.507569</td>\n",
       "      <td>0.768280</td>\n",
       "      <td>0.184767</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.272901</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.985892</td>\n",
       "      <td>0.267406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.041717</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.646628</td>\n",
       "      <td>0.491770</td>\n",
       "      <td>0.586223</td>\n",
       "      <td>0.942585</td>\n",
       "      <td>0.362255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914122</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.997252</td>\n",
       "      <td>0.422954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     0.042528    0.115681    0.394210    0.348815    0.521906    0.681970   \n",
       "std      0.102650    0.242696    0.253866    0.239522    0.138678    0.288719   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000850    0.000000    0.173387    0.137860    0.444098    0.438466   \n",
       "50%      0.002881    0.000000    0.338343    0.314815    0.507569    0.768280   \n",
       "75%      0.041717    0.125000    0.646628    0.491770    0.586223    0.942585   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000  \n",
       "mean     0.241618    0.376561    0.423589    0.625738    0.897607    0.302511  \n",
       "std      0.194973    0.379829    0.323827    0.229502    0.232131    0.202740  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.087361    0.130435    0.179389    0.510638    0.944992    0.143481  \n",
       "50%      0.184767    0.173913    0.272901    0.691489    0.985892    0.267406  \n",
       "75%      0.362255    1.000000    0.914122    0.808511    0.997252    0.422954  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    ")\n",
    "\n",
    "# Normalization and data type change\n",
    "X_train = ct.fit_transform(X_train).astype('float32')\n",
    "X_test = ct.transform(X_test).astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# Distribution of X_train feature values after normalization\n",
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b09aea",
   "metadata": {},
   "source": [
    "### Model, Predict, Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97547ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((363, 12), (41, 12), (363,), (41,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reserve data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a3283",
   "metadata": {},
   "source": [
    "### Creating the Model and Optimizing the Learning Rate\n",
    "learning rate = 0.01, batch_size = 32, dense_layers = 2, hidden_units for Dense_1 layer= 10, hidden_units for Dense_2 layer = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e0e9d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 29ms/step - loss: 298.2787 - mse: 298.2787 - val_loss: 152.8228 - val_mse: 152.8228\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 97.3451 - mse: 97.3451 - val_loss: 93.8101 - val_mse: 93.8101\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 60.6053 - mse: 60.6053 - val_loss: 66.1773 - val_mse: 66.1773\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 45.3763 - mse: 45.3763 - val_loss: 60.0252 - val_mse: 60.0252\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 43.2098 - mse: 43.2098 - val_loss: 57.9169 - val_mse: 57.9169\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 33.9256 - mse: 33.9256 - val_loss: 61.3754 - val_mse: 61.3754\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.4046 - mse: 29.4046 - val_loss: 27.6247 - val_mse: 27.6247\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.5452 - mse: 25.5452 - val_loss: 48.7888 - val_mse: 48.7888\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.3373 - mse: 25.3373 - val_loss: 23.7281 - val_mse: 23.7281\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.3041 - mse: 26.3041 - val_loss: 35.3888 - val_mse: 35.3888\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 20.7047 - mse: 20.7047 - val_loss: 41.4284 - val_mse: 41.4284\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 24.9154 - mse: 24.9154 - val_loss: 16.6363 - val_mse: 16.6363\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19.0667 - mse: 19.0667 - val_loss: 48.3958 - val_mse: 48.3958\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.9573 - mse: 21.9573 - val_loss: 14.3367 - val_mse: 14.3367\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3377 - mse: 19.3377 - val_loss: 16.6138 - val_mse: 16.6138\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2268 - mse: 20.2268 - val_loss: 21.1390 - val_mse: 21.1390\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5809 - mse: 18.5809 - val_loss: 37.9983 - val_mse: 37.9983\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1878 - mse: 20.1878 - val_loss: 14.5905 - val_mse: 14.5905\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 15.8861 - mse: 15.8861 - val_loss: 14.9666 - val_mse: 14.9666\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 19.5345 - mse: 19.5345 - val_loss: 14.5673 - val_mse: 14.5673\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.4147 - mse: 19.4147 - val_loss: 11.5271 - val_mse: 11.5271\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 15.6639 - mse: 15.6639 - val_loss: 57.3705 - val_mse: 57.3705\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.6565 - mse: 17.6565 - val_loss: 11.0761 - val_mse: 11.0761\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 16.3039 - mse: 16.3039 - val_loss: 11.2879 - val_mse: 11.2879\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 14.9067 - mse: 14.9067 - val_loss: 14.4875 - val_mse: 14.4875\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 15.2653 - mse: 15.2653 - val_loss: 34.3543 - val_mse: 34.3543\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 14.1835 - mse: 14.1835 - val_loss: 25.5908 - val_mse: 25.5908\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 14.1575 - mse: 14.1575 - val_loss: 8.8454 - val_mse: 8.8454\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 14.4119 - mse: 14.4119 - val_loss: 12.1416 - val_mse: 12.1416\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 13.7121 - mse: 13.7121 - val_loss: 23.3840 - val_mse: 23.3840\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 14.3018 - mse: 14.3018 - val_loss: 12.9378 - val_mse: 12.9378\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12.3993 - mse: 12.3993 - val_loss: 13.2346 - val_mse: 13.2346\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.8681 - mse: 11.8681 - val_loss: 8.3267 - val_mse: 8.3267\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 13.9279 - mse: 13.9279 - val_loss: 7.7896 - val_mse: 7.7896\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.2929 - mse: 13.2929 - val_loss: 8.5144 - val_mse: 8.5144\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.2223 - mse: 13.2223 - val_loss: 10.6878 - val_mse: 10.6878\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.3778 - mse: 12.3778 - val_loss: 29.7264 - val_mse: 29.7264\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.3768 - mse: 10.3768 - val_loss: 8.9452 - val_mse: 8.9452\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.0543 - mse: 12.0543 - val_loss: 9.0142 - val_mse: 9.0142\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 13.9023 - mse: 13.9023 - val_loss: 10.7485 - val_mse: 10.7485\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 10.9022 - mse: 10.9022 - val_loss: 11.6274 - val_mse: 11.6274\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11.1858 - mse: 11.1858 - val_loss: 8.4586 - val_mse: 8.4586\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 14.3373 - mse: 14.3373 - val_loss: 21.6619 - val_mse: 21.6619\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.6516 - mse: 9.6516 - val_loss: 19.5707 - val_mse: 19.5707\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.3460 - mse: 12.3460 - val_loss: 10.4339 - val_mse: 10.4339\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.6900 - mse: 9.6900 - val_loss: 14.6606 - val_mse: 14.6606\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.9585 - mse: 12.9585 - val_loss: 19.9287 - val_mse: 19.9287\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 10.4295 - mse: 10.4295 - val_loss: 10.7760 - val_mse: 10.7760\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 12.1786 - mse: 12.1786 - val_loss: 9.1996 - val_mse: 9.1996\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 11.2831 - mse: 11.2831 - val_loss: 9.7473 - val_mse: 9.7473\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.2950 - mse: 10.2950 - val_loss: 15.9271 - val_mse: 15.9271\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 11.8285 - mse: 11.8285 - val_loss: 11.8630 - val_mse: 11.8630\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.6006 - mse: 9.6006 - val_loss: 13.4773 - val_mse: 13.4773\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.2069 - mse: 10.2069 - val_loss: 28.5818 - val_mse: 28.5818\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.0311 - mse: 10.0311 - val_loss: 24.5060 - val_mse: 24.5060\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11.8886 - mse: 11.8886 - val_loss: 10.7893 - val_mse: 10.7893\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.1500 - mse: 10.1500 - val_loss: 11.4610 - val_mse: 11.4610\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.2426 - mse: 10.2426 - val_loss: 9.7152 - val_mse: 9.7152\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.7620 - mse: 9.7620 - val_loss: 13.1963 - val_mse: 13.1963\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.8371 - mse: 11.8371 - val_loss: 8.5072 - val_mse: 8.5072\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 7ms/step - loss: 9.4931 - mse: 9.4931 - val_loss: 11.9729 - val_mse: 11.9729\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11.1646 - mse: 11.1646 - val_loss: 13.9680 - val_mse: 13.9680\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11.1984 - mse: 11.1984 - val_loss: 10.0326 - val_mse: 10.0326\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.3907 - mse: 9.3907 - val_loss: 16.3984 - val_mse: 16.3984\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.9560 - mse: 9.9560 - val_loss: 10.9971 - val_mse: 10.9971\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 10.6492 - mse: 10.6492 - val_loss: 13.7719 - val_mse: 13.7719\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12.0578 - mse: 12.0578 - val_loss: 13.0683 - val_mse: 13.0683\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.0645 - mse: 8.0645 - val_loss: 12.1583 - val_mse: 12.1583\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.6328 - mse: 9.6328 - val_loss: 13.0597 - val_mse: 13.0597\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.8294 - mse: 9.8294 - val_loss: 19.7126 - val_mse: 19.7126\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.5169 - mse: 10.5169 - val_loss: 15.7204 - val_mse: 15.7204\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11.0752 - mse: 11.0752 - val_loss: 10.5293 - val_mse: 10.5293\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.1051 - mse: 9.1051 - val_loss: 10.2725 - val_mse: 10.2725\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 9.4462 - mse: 9.4462 - val_loss: 9.5197 - val_mse: 9.5197\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.4152 - mse: 10.4152 - val_loss: 24.5249 - val_mse: 24.5249\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.5394 - mse: 8.5394 - val_loss: 9.8981 - val_mse: 9.8981\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 10.2001 - mse: 10.2001 - val_loss: 10.7774 - val_mse: 10.7774\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.1633 - mse: 9.1633 - val_loss: 20.6301 - val_mse: 20.6301\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.7947 - mse: 10.7947 - val_loss: 10.2169 - val_mse: 10.2169\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.7543 - mse: 8.7543 - val_loss: 18.1104 - val_mse: 18.1104\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.1691 - mse: 9.1691 - val_loss: 9.6081 - val_mse: 9.6081\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.5266 - mse: 10.5266 - val_loss: 15.0998 - val_mse: 15.0998\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.9316 - mse: 9.9316 - val_loss: 9.0088 - val_mse: 9.0088\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.9367 - mse: 9.9367 - val_loss: 14.7333 - val_mse: 14.7333\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11.6390 - mse: 11.6390 - val_loss: 13.3909 - val_mse: 13.3909\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.7167 - mse: 8.7167 - val_loss: 12.1524 - val_mse: 12.1524\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.7511 - mse: 7.7511 - val_loss: 15.9152 - val_mse: 15.9152\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 10.1006 - mse: 10.1006 - val_loss: 10.1940 - val_mse: 10.1940\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.0072 - mse: 10.0072 - val_loss: 9.6030 - val_mse: 9.6030\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 10.2613 - mse: 10.2613 - val_loss: 9.2150 - val_mse: 9.2150\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.7142 - mse: 9.7142 - val_loss: 11.4908 - val_mse: 11.4908\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.5385 - mse: 9.5385 - val_loss: 11.1983 - val_mse: 11.1983\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.9093 - mse: 9.9093 - val_loss: 19.1432 - val_mse: 19.1432\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.2815 - mse: 9.2815 - val_loss: 24.3627 - val_mse: 24.3627\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.7218 - mse: 8.7218 - val_loss: 9.8969 - val_mse: 9.8969\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.4256 - mse: 10.4256 - val_loss: 14.0433 - val_mse: 14.0433\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.9299 - mse: 8.9299 - val_loss: 11.7731 - val_mse: 11.7731\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11.1363 - mse: 11.1363 - val_loss: 11.3113 - val_mse: 11.3113\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.6713 - mse: 10.6713 - val_loss: 10.9225 - val_mse: 10.9225\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.1862 - mse: 8.1862 - val_loss: 17.2447 - val_mse: 17.2447\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Building the model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(units=10, activation='relu', input_shape=(X_train.shape[1],), name='Dense_1'),\n",
    "  tf.keras.layers.Dense(units=100, activation='relu', name='Dense_2'),\n",
    "  tf.keras.layers.Dense(units=1, name='Prediction')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.mean_squared_error,\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01),\n",
    "    metrics = ['mse']\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083513b3",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0719df2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.235537, 24.89756)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the mean value of training and validation data\n",
    "y_train.mean(), y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feed7faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Test data \n",
      "\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 16.9001 - mse: 16.9001\n",
      "\n",
      "Model loss on test set: 16.900070190429688\n",
      "Model mean squared error on test set: 16.90\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "print(\"Evaluation on Test data \\n\")\n",
    "loss, mse = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"\\nModel loss on test set: {loss}\")\n",
    "print(f\"Model mean squared error on test set: {(mse):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0b6bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves\n",
    "pd.DataFrame(history.history).plot(figsize=(6, 4), xlabel=\"Epochs\", ylabel=\"Loss\", title='Loss Curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f80216",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1678307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([18.972794], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# View the first prediction\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046e6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
